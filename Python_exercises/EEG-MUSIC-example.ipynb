{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "import mne # See docs: https://mne.tools/dev/generated/mne.io.read_raw_edf.html\n",
    "import pyedflib # See docs: https://pyedflib.readthedocs.io/en/latest/\n",
    "from pyedflib import highlevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_vagabond_colors = [\"#fffdfa\", \"#fef8f0\", \"#fbe4cb\", \"#e8c29d\", \n",
    "                              \"#9a7b56\", \"#2b322e\", \"#f0f2f1\"]\n",
    "vagabond_colors = [\"#cec5c1\", \"#9f8f7f\", \"#924a42\", \"#5a2028\",\n",
    "                   \"#a4b9b1\", \"#4ea7a6\", \"#026d73\", \"#06494f\"]\n",
    "gmk_ursa = [\"A9907E\", \"F3DEBA\", \"ABC4AA\", \"675D50\"]\n",
    "\n",
    "rc('font', **{'family':'serif', 'serif':['Computer Modern']})\n",
    "rc('text', usetex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the file path as a string for easier use\n",
    "file_path = '/Users/jacksonpowell/Documents/GitHub/learningML/data_files/sub-01_ses-01_task-musicTherapy_eeg.edf'; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"highlevel\" takes data from .edf file (see docs in includes) and saves in signals (np.array of numbers) and headers (dicts)\n",
    "signals, signal_headers, data_header = highlevel.read_edf(file_path); \n",
    "\n",
    "# Printing to see data and size\n",
    "print(signal_headers[0]);  \n",
    "print(signals[0].shape); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(signal, header, window, color = None, tag = None):\n",
    "\n",
    "    if not tag: \n",
    "        tag = \"\"; \n",
    "\n",
    "    frequency = header[\"sample_frequency\"]; # Takes frequency value from header dict\n",
    "\n",
    "    total_time_seconds = len(signal) / frequency; # Storing total time in seconds\n",
    "    total_time_mins = len(signal) / frequency / 60; # Storing total time in minutes \n",
    "    time = np.linspace(0, total_time_seconds, len(signal), endpoint=True); # Creating x-axis based on frequency\n",
    "\n",
    "    start_time = window[0]; # Taking first value in window array, aka the start of the zoomed frame\n",
    "    stop_time = window[1]; # Taking second value in window array, aka the end of the zoomed frame\n",
    "\n",
    "    time_frame = stop_time - start_time; # Total time of zoomed frame\n",
    "    zoomed_frame = int(time_frame * frequency); # Number of data points in zoomed frame\n",
    "    zoomed_signal = signal[int(start_time * frequency) : int(stop_time * frequency)]; # Subset of signal plotted\n",
    "    zoomed_time = np.linspace(start_time, stop_time, zoomed_frame, endpoint=True); # x-axis for zoomed plot\n",
    "\n",
    "    # Plot specificiations\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 4)); \n",
    "\n",
    "    ax1.plot(time, signal, color = color, linewidth = 0.3); \n",
    "    ax1.set_xlabel('time (s)'); \n",
    "    ax1.set_ylabel('voltage (uV)'); \n",
    "    ax1.set_title(f\"total frame, {tag} {header['label']}\"); \n",
    "    ax1.set_facecolor(background_vagabond_colors[0])\n",
    "\n",
    "    ax2.plot(zoomed_time, zoomed_signal, color = color, linewidth = 0.3); \n",
    "    ax2.set_xlabel('time (s)'); \n",
    "    ax2.set_ylabel('voltage (uV)'); \n",
    "    ax2.set_title(f\"from {start_time}s to {stop_time}s, {tag} {header['label']}\"); \n",
    "    ax2.set_facecolor(background_vagabond_colors[0])\n",
    "\n",
    "    plt.show(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 100; \n",
    "stop_time = 110; \n",
    "\n",
    "for i in range(0, len(signal_headers), 1): # Plotting over all electrodes\n",
    "    # Information is the signal to be plotted, its corresponding header, and then a zoomed in window\n",
    "    # I.e., if you want to see a zoomed in plot from seconds 0 to 5, the third argument would be [0,5]\n",
    "    plot_signal(signals[i], signal_headers[i], [start_time, stop_time]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_signal(all_signals, all_headers, tag = None): \n",
    "\n",
    "    figure_length = len(all_signals); # In inches (scaling based on # of electrodes)\n",
    "    plt.figure(figsize = (figure_length, 7)); \n",
    "\n",
    "    for i in range(0, len(all_signals), 1): # Plotting over all electrodes\n",
    "        # Information is the signal to be plotted, its corresponding header, and then a zoomed in window\n",
    "        # I.e., if you want to see a zoomed in plot from seconds 0 to 5, the third argument would be [0,5] \n",
    "\n",
    "        if not tag: \n",
    "            tag = \"\"; \n",
    "\n",
    "        frequency = all_headers[i][\"sample_frequency\"]; # Takes frequency value from header dict\n",
    "\n",
    "        total_time_seconds = len(all_signals[i]) / frequency; # Storing total time in seconds\n",
    "        total_time_mins = len(all_signals[i]) / frequency / 60; # Storing total time in minutes \n",
    "        time = np.linspace(0, total_time_seconds, len(signals[0]), endpoint=True); # Creating x-axis based on frequency\n",
    "\n",
    "        # Plot specificiations\n",
    "        len(all_signals)\n",
    "\n",
    "        plt.tight_layout(h_pad = 2)\n",
    "        ax = plt.subplot(4, 2, i + 1)\n",
    "        \n",
    "        ax.plot(time, all_signals[i], linewidth = 0.3, color = vagabond_colors[i % len(vagabond_colors)]); \n",
    "        ax.set_xlabel('time (s)', fontsize = 8); \n",
    "        ax.set_ylabel('voltage (uV)', fontsize = 8); \n",
    "        ax.set_title(f\"{tag} {all_headers[i]['label']}\", fontsize = 10); \n",
    "\n",
    "        ax.set_facecolor(background_vagabond_colors[6])\n",
    "\n",
    "        ax.margins(x = 0); \n",
    "\n",
    "        plt.xticks(fontsize=8); \n",
    "        plt.yticks(fontsize=8); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_signal(signals, signal_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_num = 5; # Which signal we want to filter\n",
    "\n",
    "# A zoomed in timeframe, if we want to look closely at a segment of the wave form\n",
    "start_time = 625; \n",
    "stop_time = 635; \n",
    "\n",
    "# Docs: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html\n",
    "# Bandpass filter with delta F freq values contained in [f1,f2]---functions as corner frequencies, like in electronics\n",
    "bandpass = signal.butter(1, [2, 5], 'bandpass', fs=1024, output='sos'); \n",
    "filtered_signal = signal.sosfilt(bandpass, signals[signal_num]); \n",
    "\n",
    "# Plotting to compare filtered and unfiltered data\n",
    "plot_signal(filtered_signal, signal_headers[signal_num], [start_time, stop_time], 'darkgreen', tag = \"filtered\"); \n",
    "plot_signal(signals[signal_num], signal_headers[signal_num], [start_time, stop_time]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_signals = np.zeros((len(signals), len(signals[0]))); \n",
    "\n",
    "bandpass = signal.butter(1, [2, 5], 'bandpass', fs=1024, output='sos'); \n",
    "\n",
    "for i in range(0, len(signals), 1):\n",
    "    filtered_signals[i] = signal.sosfilt(bandpass, signals[i]); \n",
    "\n",
    "# Plotting to compare filtered and unfiltered data\n",
    "plot_all_signal(filtered_signals, signal_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docs: https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to add that are pre-built: \n",
    "    #   Docs: https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "    #   Entropy, differential entropy\n",
    "    #   Trimmed statistics\n",
    "    #   Median absolute deviation\n",
    "    #   Cumulative and relative frequency\n",
    "\n",
    "# Features to add by user: \n",
    "    #   Spikes, polyspikes---value and number\n",
    "    #   Spike and wave\n",
    "    #   Sharp wave complexes\n",
    "    #   Slow cortical potentials\n",
    "    #   Sensorimotor rhythms\n",
    "    #   P300 event-related potential\n",
    "    #   Steady-state visual evoked potentials\n",
    "    #   Error-related negative evoked potentials\n",
    "\n",
    "def extract_allFeatures(all_signals, all_headers):\n",
    "\n",
    "    figure_length = len(all_signals); # In inches (scaling based on # of electrodes)\n",
    "    plt.figure(figsize = (figure_length, 7)); \n",
    "\n",
    "    features_matrix = np.zeros((len(signals), 6)) # Initializing 2D, x by 1 array\n",
    "    vec = DictVectorizer(); \n",
    "\n",
    "    # The list of features, in a dictionary, that we will extract\n",
    "    for i in range(0, len(all_signals), 1):\n",
    "\n",
    "        local_features_dict = {\n",
    "                    'label' : all_headers[i]['label'], \n",
    "                    'mean' : 0, \n",
    "                    'std_dev': 0,\n",
    "                    'skewness' : 0,\n",
    "                    'kurt' : 0, \n",
    "                    'dominant_freq' : 0\n",
    "                    }\n",
    "\n",
    "        # Populating the features dictionary \n",
    "        local_features_dict['mean'] = np.mean(all_signals[i]); \n",
    "\n",
    "        std_dev = np.std(all_signals[i]); \n",
    "        local_features_dict['std_dev'] = std_dev; \n",
    "\n",
    "        local_features_dict['skewness'] = skew(all_signals[i]); \n",
    "        local_features_dict['kurt'] = kurtosis(all_signals[i]); \n",
    "\n",
    "        # Normalizing the signal before fft processing\n",
    "        normalized_signal = (all_signals[i] - np.mean(all_signals[i])) / np.std(all_signals[i])\n",
    "\n",
    "        # The total number and time between data points\n",
    "        N = len(all_signals[i]); \n",
    "        delta_t = 1 / all_headers[i]['sample_frequency']; \n",
    "\n",
    "\n",
    "        # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        # User defined features  \n",
    "        # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "        j = 0; # Used to index through the array\n",
    "        num_spikes = 0; # Will store the number of spikes in this segment \n",
    "        while j < len(all_signals[i]):\n",
    "            if all_signals[i][j] > 3 * std_dev: # Begins counting when an amplitude that's 3 std dev above the mean is found\n",
    "                start_pos = j; # Saves the starting time (of high amplitude)\n",
    "                while all_signals[i][j] > 3 * std_dev and not j == len(all_signals[i]) - 1: # Added second condition because it would break when reaching the end of the list\n",
    "                    j += 1; \n",
    "                stop_pos = j; # Stores the ending time (of high amplitude)\n",
    "        \n",
    "                duration = (stop_pos - start_pos) * delta_t; # Computes the duration of the high amplitude (in seconds)\n",
    "                if duration > 0.05: # 50 ms currently \n",
    "                    num_spikes += 1; # Counts the number of spikes that persist for more than x ms \n",
    "            j += 1; # Continues on through the list\n",
    "        \n",
    "        print(f\"{all_headers[i]['label']} had {num_spikes}\"); \n",
    "\n",
    "        # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        # FFT  \n",
    "        # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "        # Running fft and solving for the frequency domain (x axis)\n",
    "        fft_values = fft(normalized_signal); \n",
    "        freq_domain = np.fft.fftfreq(N, d = delta_t); \n",
    "        fft_magnitude = np.abs(fft_values); \n",
    "        \n",
    "        # Dominant frequency found as the highest magnitude fft value and its corresponding location in the frequency domain\n",
    "        local_features_dict['dominant_freq'] = freq_domain[np.argmax(fft_magnitude)]; \n",
    "        \n",
    "        features_vec = vec.fit_transform(local_features_dict).toarray(); \n",
    "        vec.get_feature_names_out()\n",
    "\n",
    "        features_matrix[i] = features_vec; \n",
    "\n",
    "\n",
    "        # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        # Plotting \n",
    "        # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "        plt.tight_layout(h_pad = 2)\n",
    "        ax = plt.subplot(4, 2, i + 1)\n",
    "        \n",
    "        # I don't really understand what // does but every online resource uses this \n",
    "        ax.plot(freq_domain[:N//2], abs(fft_values[0:N//2]), linewidth = 0.5, color = vagabond_colors[i % len(vagabond_colors)]); \n",
    "        ax.set_xlabel('freq (hz)', fontsize = 8); \n",
    "        ax.set_title(f\"{local_features_dict['label']}, dom_freq = {round(local_features_dict['dominant_freq'], 2)} hz\", fontsize = 10); \n",
    "        plt.xticks(fontsize = 8); \n",
    "        plt.yticks(fontsize = 8); \n",
    "\n",
    "    return features_matrix; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features matrix\n",
    "\n",
    "features = extract_allFeatures(signals, signal_headers); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to add that are pre-built: \n",
    "    #   Docs: https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "    #   Entropy, differential entropy\n",
    "    #   Trimmed statistics\n",
    "    #   Median absolute deviation\n",
    "    #   Cumulative and relative frequency\n",
    "\n",
    "# Features to add by user: \n",
    "    #   Spikes, polyspikes---value and number\n",
    "    #   Spike and wave\n",
    "    #   Sharp wave complexes\n",
    "    #   Slow cortical potentials\n",
    "    #   Sensorimotor rhythms\n",
    "    #   P300 event-related potential\n",
    "    #   Steady-state visual evoked potentials\n",
    "    #   Error-related negative evoked potentials\n",
    "\n",
    "def extractFeatures(signal, header):\n",
    "\n",
    "    # This is used to convert the dictionary to a vector\n",
    "    # Notably, there seems to be an issue where dictionary order is not preserved, which \n",
    "    # can be a bit inconvenient and confusing when trying to test data. It may be wise to\n",
    "    # abandon dictionaries and store simply as vectors---which is a bit less easy to read,\n",
    "    # but may prevent issues later. \n",
    "    vec = DictVectorizer(); \n",
    "\n",
    "    # The list of features, in a dictionary, that we will extract\n",
    "\n",
    "    local_features_dict = {'label' : header['label'], \n",
    "                'mean' : 0, \n",
    "                'std_dev': 0,\n",
    "                'skewness' : 0,\n",
    "                'kurt' : 0, \n",
    "                'dominant_freq' : 0}\n",
    "\n",
    "    # Populating the features dictionary \n",
    "    local_features_dict['mean'] = np.mean(signal); \n",
    "\n",
    "    std_dev = np.std(signal); \n",
    "    local_features_dict['std_dev'] = std_dev; \n",
    "\n",
    "    local_features_dict['skewness'] = skew(signal); \n",
    "    local_features_dict['kurt'] = kurtosis(signal); \n",
    "\n",
    "    # Normalizing the signal before fft processing\n",
    "    normalized_signal = (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "    # The total number and time between data points\n",
    "    N = len(signal); \n",
    "    delta_t = 1 / header['sample_frequency']; \n",
    "\n",
    "\n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # User defined features  \n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "    # NOTE: A wiser way to do this would be to take the derivative, and calculate the period when the \n",
    "    # derivative is greater than x for duration y (to mark the start time), etc. Right now we define \n",
    "    # the start time by magnitude, which is technically not the beginning of the spike. Plus, it might\n",
    "    # be helpful for noiser data (i.e., right now we define by std dev above the mean, which may vary\n",
    "    # depending on how noisy the data is). \n",
    "\n",
    "    j = 0; # Used to index through the array\n",
    "    num_spikes = 0; # Will store the number of spikes in this segment \n",
    "    while j < len(signal):\n",
    "        if signal[j] > 3 * std_dev: # Begins counting when an amplitude that's 3 std dev above the mean is found\n",
    "            start_pos = j; # Saves the starting time (of high amplitude)\n",
    "            while signal[j] > 3 * std_dev and not j == len(signal) - 1: # Added second condition because it would break when reaching the end of the list\n",
    "                j += 1; \n",
    "            stop_pos = j; # Stores the ending time (of high amplitude)\n",
    "    \n",
    "            duration = (stop_pos - start_pos) * delta_t; # Computes the duration of the high amplitude (in seconds)\n",
    "            if duration > 0.05: # 50 ms currently \n",
    "                num_spikes += 1; # Counts the number of spikes that persist for more than x ms \n",
    "        j += 1; # Continues on through the list\n",
    "    \n",
    "\n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # FFT  \n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "    # Running fft and solving for the frequency domain (x axis)\n",
    "    fft_values = fft(normalized_signal); \n",
    "    freq_domain = np.fft.fftfreq(N, d = delta_t); \n",
    "    fft_magnitude = np.abs(fft_values); \n",
    "    \n",
    "    # Dominant frequency found as the highest magnitude fft value and its corresponding location in the frequency domain\n",
    "    local_features_dict['dominant_freq'] = freq_domain[np.argmax(fft_magnitude)]; \n",
    "    \n",
    "    features_vec = vec.fit_transform(local_features_dict).toarray(); \n",
    "    vec.get_feature_names_out()\n",
    "\n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # Plotting \n",
    "    # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "\n",
    "    return features_vec, local_features_dict; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_features, window_dictionary = extractFeatures(signals[0], signal_headers[0]); \n",
    "\n",
    "print(window_dictionary)\n",
    "print(window_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_duration = 1.500; # Define rolling scanner duration in s\n",
    "scan_overlap = 0.500; # Define overlap between windows in s\n",
    "\n",
    "frequency = signal_headers[0][\"sample_frequency\"]; \n",
    "\n",
    "scan_duration_indexes = int(scan_duration * frequency); # Converts the duration to indices\n",
    "scan_overlap_indexes = int(scan_overlap * frequency); # Converts the overlap to indices\n",
    "\n",
    "plot_signal(signals[0], signal_headers[0], [200, 350], color = vagabond_colors[2]); # Temporary plotting just to test\n",
    "\n",
    "signal = signals[0]; # The signal we will analyze (should optimize this bit later)\n",
    "header = signal_headers[0]; # The corresponding header\n",
    "total_window_count = math.ceil(len(signal) / (scan_duration_indexes - scan_overlap)); # The number of windows we will analyze (height of features matrix)\n",
    "\n",
    "features_matrix = np.zeros((total_window_count,6)) # NOTE: need to replace with the number of features later\n",
    "\n",
    "scan_start = 0; # The starting index for each individual window\n",
    "window_counter = 0; # Will use this to index through features matrix\n",
    "while scan_start < len(signal): \n",
    "\n",
    "    if scan_start + scan_duration_indexes < len(signal): # Extracts width of window \n",
    "        temp_window = signal[scan_start:scan_start + scan_duration_indexes]; \n",
    "    else: # Extracts from start to end in the event that we are close to end of the total time and cannot fit in a full window\n",
    "        # It's not clear to me if this is good to do, or if we should drop this data point---i.e., it may provide odd values if weighted equally\n",
    "        temp_window = signal[scan_start:]; \n",
    "    \n",
    "    window_features, window_dictionary = extractFeatures(temp_window, header); \n",
    "    features_matrix[window_counter] = window_features; # Adding vector to features matrix\n",
    "\n",
    "    scan_start += int(scan_duration_indexes - scan_overlap); # Setting the new start time for the next window\n",
    "    window_counter += 1; # Indexing up for our counter \n",
    "\n",
    "print(features_matrix.shape)\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# Plotting\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "mean_over_windows = features_matrix[:,1]\n",
    "x = np.linspace(0, 100, len(features_matrix))\n",
    "print(x.shape, mean_over_windows.shape)\n",
    "\n",
    "plt.plot(x, mean_over_windows, color = vagabond_colors[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
